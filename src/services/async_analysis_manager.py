#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å¼‚æ­¥æˆªå›¾åˆ†æç®¡ç†å™¨

è´Ÿè´£åè°ƒæˆªå›¾è·å–ã€VLMåˆ†æå’Œç»“æœè¾“å‡ºçš„æ•´ä¸ªå¼‚æ­¥æµç¨‹ã€‚
æä¾›å®æ—¶åˆ†æã€æ‰¹é‡åˆ†æå’Œæ™ºèƒ½è°ƒåº¦åŠŸèƒ½ã€‚
"""

import asyncio
import time
import json
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any, Callable, Coroutine
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor

import numpy as np
from loguru import logger

from .ollama_vlm import OllamaVLMService
from .connection import ConnectionService
from ..models import (
    VLMResult, AnalysisResult, Element, ActionSuggestion,
    VLMError, ScreenshotError
)
from ..utils.config import ConfigManager
from ..utils.helpers import save_screenshot, format_timestamp


@dataclass
class AnalysisTask:
    """åˆ†æä»»åŠ¡æ•°æ®ç±»"""
    task_id: str
    screenshot: np.ndarray
    timestamp: float
    analysis_type: str = "game_analysis"
    custom_prompt: Optional[str] = None
    priority: int = 1
    callback: Optional[Callable] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


@dataclass
class AnalysisRecord:
    """åˆ†æè®°å½•æ•°æ®ç±»"""
    task_id: str
    timestamp: float
    screenshot_path: str
    vlm_result: VLMResult
    analysis_duration: float
    user_feedback: Optional[str] = None
    accuracy_score: Optional[float] = None


class AsyncAnalysisManager:
    """å¼‚æ­¥æˆªå›¾åˆ†æç®¡ç†å™¨"""
    
    def __init__(self, 
                 config_manager: ConfigManager,
                 connection_service: ConnectionService,
                 max_concurrent_tasks: int = 3,
                 analysis_history_limit: int = 100):
        """
        åˆå§‹åŒ–å¼‚æ­¥åˆ†æç®¡ç†å™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
            connection_service: è¿æ¥æœåŠ¡
            max_concurrent_tasks: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
            analysis_history_limit: åˆ†æå†å²è®°å½•é™åˆ¶
        """
        self.config = config_manager
        self.connection = connection_service
        self.max_concurrent_tasks = max_concurrent_tasks
        self.analysis_history_limit = analysis_history_limit
        
        # VLMæœåŠ¡
        self.vlm_service = None
        
        # ä»»åŠ¡é˜Ÿåˆ—å’Œç®¡ç†
        self.task_queue = asyncio.Queue()
        self.active_tasks = {}
        self.completed_tasks = {}
        self.analysis_history = []
        self.history_limit = analysis_history_limit
        
        # æ§åˆ¶æ ‡å¿—
        self.is_running = False
        self.auto_analysis_enabled = False
        self.analysis_interval = 5.0  # è‡ªåŠ¨åˆ†æé—´éš”ï¼ˆç§’ï¼‰
        
        # çº¿ç¨‹æ± ç”¨äºCPUå¯†é›†å‹ä»»åŠ¡
        self.thread_pool = ThreadPoolExecutor(max_workers=2)
        
        # ç»“æœè¾“å‡ºå›è°ƒ
        self.result_callbacks = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "failed_analyses": 0,
            "average_duration": 0.0,
            "prompt_optimizations": 0
        }
    
    async def initialize(self) -> bool:
        """
        åˆå§‹åŒ–åˆ†æç®¡ç†å™¨
        
        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            # åˆå§‹åŒ–VLMæœåŠ¡
            vlm_config = self.config.get_vlm_config()
            self.vlm_service = OllamaVLMService(
                host=vlm_config.host,
                port=vlm_config.port,
                model=vlm_config.model,
                timeout=vlm_config.timeout,
                image_max_size=tuple(vlm_config.image_max_size),
                image_quality=vlm_config.image_quality
            )
            
            if not await self.vlm_service.initialize():
                logger.error("VLMæœåŠ¡åˆå§‹åŒ–å¤±è´¥")
                return False
            
            # å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨
            self.is_running = True
            try:
                asyncio.create_task(self._task_processor())
            except RuntimeError as e:
                if "cannot schedule new futures after shutdown" in str(e):
                    logger.warning("äº‹ä»¶å¾ªç¯å·²å…³é—­ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨")
                    self.is_running = False
                    return False
                else:
                    raise
            
            # æ·»åŠ é»˜è®¤ç»“æœè¾“å‡ºå›è°ƒ
            self.add_result_callback(self._default_result_callback)
            
            logger.info("å¼‚æ­¥åˆ†æç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"å¼‚æ­¥åˆ†æç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def start(self) -> bool:
        """å¯åŠ¨å¼‚æ­¥åˆ†æç®¡ç†å™¨"""
        return await self.initialize()
    
    async def stop(self) -> None:
        """åœæ­¢å¼‚æ­¥åˆ†æç®¡ç†å™¨"""
        try:
            logger.info("æ­£åœ¨åœæ­¢å¼‚æ­¥åˆ†æç®¡ç†å™¨...")
            
            # åœæ­¢æ¥æ”¶æ–°ä»»åŠ¡
            self.is_running = False
            self.auto_analysis_enabled = False
            
            # æ¸…ç©ºä»»åŠ¡é˜Ÿåˆ—ï¼Œé¿å…æ–°ä»»åŠ¡è¢«å¤„ç†
            queue_size = self.task_queue.qsize()
            if queue_size > 0:
                logger.info(f"æ¸…ç©ºä»»åŠ¡é˜Ÿåˆ—ä¸­çš„ {queue_size} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
                while not self.task_queue.empty():
                    try:
                        self.task_queue.get_nowait()
                    except asyncio.QueueEmpty:
                        break
            
            # ç­‰å¾…æ´»åŠ¨ä»»åŠ¡å®Œæˆï¼ˆæœ€å¤šç­‰å¾…30ç§’ï¼‰
            wait_start = time.time()
            while self.active_tasks and (time.time() - wait_start) < 30:
                logger.info(f"ç­‰å¾… {len(self.active_tasks)} ä¸ªæ´»åŠ¨ä»»åŠ¡å®Œæˆ...")
                await asyncio.sleep(1.0)
            
            # å¦‚æœè¿˜æœ‰æ´»åŠ¨ä»»åŠ¡ï¼Œå¼ºåˆ¶æ¸…ç†
            if self.active_tasks:
                logger.warning(f"å¼ºåˆ¶æ¸…ç† {len(self.active_tasks)} ä¸ªæœªå®Œæˆçš„ä»»åŠ¡")
                self.active_tasks.clear()
            
            # åœæ­¢VLMæœåŠ¡
            if self.vlm_service:
                try:
                    await self.vlm_service.stop()
                except Exception as e:
                    logger.warning(f"åœæ­¢VLMæœåŠ¡æ—¶å‡ºé”™: {e}")
            
            # å…³é—­çº¿ç¨‹æ± 
            if self.thread_pool:
                try:
                    self.thread_pool.shutdown(wait=True)  # ç­‰å¾…çº¿ç¨‹æ± ä¸­çš„ä»»åŠ¡å®Œæˆ
                    logger.info("çº¿ç¨‹æ± å·²å®‰å…¨å…³é—­")
                except Exception as e:
                    logger.warning(f"å…³é—­çº¿ç¨‹æ± æ—¶å‡ºé”™: {e}")
            
            logger.info("å¼‚æ­¥åˆ†æç®¡ç†å™¨å·²åœæ­¢")
            
        except Exception as e:
            logger.error(f"åœæ­¢å¼‚æ­¥åˆ†æç®¡ç†å™¨å¤±è´¥: {e}")
    
    async def start_auto_analysis(self, interval: float = 5.0) -> None:
        """
        å¯åŠ¨è‡ªåŠ¨æˆªå›¾åˆ†æ
        
        Args:
            interval: åˆ†æé—´éš”ï¼ˆç§’ï¼‰
        """
        self.analysis_interval = interval
        self.auto_analysis_enabled = True
        
        # å¯åŠ¨è‡ªåŠ¨åˆ†æä»»åŠ¡
        try:
            asyncio.create_task(self._auto_analysis_loop())
            logger.info(f"è‡ªåŠ¨æˆªå›¾åˆ†æå·²å¯åŠ¨ï¼Œé—´éš”: {interval}ç§’")
        except RuntimeError as e:
            if "cannot schedule new futures after shutdown" in str(e):
                logger.warning("äº‹ä»¶å¾ªç¯å·²å…³é—­ï¼Œæ— æ³•å¯åŠ¨è‡ªåŠ¨åˆ†æ")
                self.auto_analysis_enabled = False
            else:
                raise
    
    async def stop_auto_analysis(self) -> None:
        """åœæ­¢è‡ªåŠ¨æˆªå›¾åˆ†æ"""
        self.auto_analysis_enabled = False
        logger.info("è‡ªåŠ¨æˆªå›¾åˆ†æå·²åœæ­¢")
    
    async def analyze_screenshot(self, 
                               screenshot: Optional[np.ndarray] = None,
                               analysis_type: str = "game_analysis",
                               custom_prompt: Optional[str] = None,
                               priority: int = 1,
                               callback: Optional[Callable] = None) -> str:
        """
        æäº¤æˆªå›¾åˆ†æä»»åŠ¡
        
        Args:
            screenshot: æˆªå›¾æ•°æ®ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨è·å–
            analysis_type: åˆ†æç±»å‹
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            priority: ä»»åŠ¡ä¼˜å…ˆçº§
            callback: å®Œæˆå›è°ƒå‡½æ•°
            
        Returns:
            str: ä»»åŠ¡ID
        """
        try:
            # è·å–æˆªå›¾
            if screenshot is None:
                screenshot = await self._capture_screenshot()
            
            # åˆ›å»ºä»»åŠ¡
            task_id = f"analysis_{int(time.time() * 1000)}"
            task = AnalysisTask(
                task_id=task_id,
                screenshot=screenshot,
                timestamp=time.time(),
                analysis_type=analysis_type,
                custom_prompt=custom_prompt,
                priority=priority,
                callback=callback
            )
            
            # æ·»åŠ åˆ°é˜Ÿåˆ—
            await self.task_queue.put(task)
            logger.info(f"åˆ†æä»»åŠ¡å·²æäº¤: {task_id}")
            
            return task_id
            
        except Exception as e:
            logger.error(f"æäº¤åˆ†æä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def get_analysis_result(self, task_id: str, timeout: float = 60.0) -> Optional[VLMResult]:
        """
        è·å–åˆ†æç»“æœ
        
        Args:
            task_id: ä»»åŠ¡ID
            timeout: è¶…æ—¶æ—¶é—´
            
        Returns:
            VLMResult: åˆ†æç»“æœï¼Œå¦‚æœè¶…æ—¶æˆ–å¤±è´¥åˆ™è¿”å›None
        """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if task_id in self.completed_tasks:
                return self.completed_tasks[task_id]
            
            await asyncio.sleep(0.1)
        
        logger.warning(f"è·å–åˆ†æç»“æœè¶…æ—¶: {task_id}")
        return None
    
    def add_result_callback(self, callback: Callable[[str, VLMResult], None]) -> None:
        """
        æ·»åŠ ç»“æœå›è°ƒå‡½æ•°
        
        Args:
            callback: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶(task_id, result)å‚æ•°
        """
        self.result_callbacks.append(callback)
    
    async def optimize_prompts(self, user_feedback: Optional[str] = None) -> bool:
        """
        åŸºäºå†å²æ•°æ®ä¼˜åŒ–æç¤ºè¯
        
        Args:
            user_feedback: ç”¨æˆ·åé¦ˆ
            
        Returns:
            bool: ä¼˜åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ£€æŸ¥æç¤ºè¯ç®¡ç†å™¨çš„ä½¿ç”¨ç»Ÿè®¡
            from ..utils.prompt_manager import get_prompt_manager
            prompt_manager = get_prompt_manager()
            stats = prompt_manager.get_prompt_stats()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æç¤ºè¯ä½¿ç”¨æ•°æ®
            has_sufficient_data = False
            for category, category_stats in stats['categories'].items():
                if category_stats['total_usage'] >= 3:  # ä½¿ç”¨é…ç½®ä¸­çš„é˜ˆå€¼
                    has_sufficient_data = True
                    break
            
            if not has_sufficient_data:
                logger.warning("æç¤ºè¯ä½¿ç”¨æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œä¼˜åŒ–ã€‚è¯·å…ˆä½¿ç”¨æ¸¸æˆåŠ©æ‰‹åŠŸèƒ½ç§¯ç´¯æ•°æ®ã€‚")
                return False
            
            # åŸºäºæç¤ºè¯ç»Ÿè®¡æ•°æ®è¿›è¡Œä¼˜åŒ–
            optimization_performed = False
            
            for category, category_stats in stats['categories'].items():
                if category_stats['total_usage'] >= 3:
                    success_rate = category_stats['avg_success_rate']
                    response_time = category_stats['avg_response_time']
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
                    needs_optimization = False
                    optimization_reason = ""
                    
                    if success_rate < 0.7:
                        needs_optimization = True
                        optimization_reason = f"æˆåŠŸç‡è¾ƒä½ ({success_rate:.1%})"
                    elif response_time > 8.0:
                        needs_optimization = True
                        optimization_reason = f"å“åº”æ—¶é—´è¾ƒé•¿ ({response_time:.1f}s)"
                    
                    if needs_optimization:
                        logger.info(f"æ­£åœ¨ä¼˜åŒ–æç¤ºè¯ {category}: {optimization_reason}")
                        
                        # è§¦å‘æç¤ºè¯ç®¡ç†å™¨çš„ä¼˜åŒ–ï¼ˆé¿å…æ­»é”ï¼‰
                        try:
                            prompt_manager._optimize_prompts()
                            optimization_performed = True
                        except Exception as e:
                            logger.error(f"æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {e}")
            
            if not optimization_performed:
                logger.info("å½“å‰æç¤ºè¯æ€§èƒ½è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–")
                return True
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["prompt_optimizations"] += 1
            
            logger.info("æç¤ºè¯ä¼˜åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {e}")
            return False
    
    async def get_analysis_statistics(self) -> Dict[str, Any]:
        """
        è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        stats = self.stats.copy()
        stats.update({
            "queue_size": self.task_queue.qsize(),
            "active_tasks_count": len(self.active_tasks),
            "history_count": len(self.analysis_history),
            "auto_analysis_enabled": self.auto_analysis_enabled,
            "vlm_service_available": self.vlm_service.is_available if self.vlm_service else False
        })
        return stats
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        stats = self.stats.copy()
        stats.update({
            "queue_size": self.task_queue.qsize(),
            "active_tasks_count": len(self.active_tasks),
            "history_count": len(self.analysis_history),
            "auto_analysis_enabled": self.auto_analysis_enabled,
            "vlm_service_available": self.vlm_service.is_available if self.vlm_service else False
        })
        # æ·»åŠ æµ‹è¯•éœ€è¦çš„å­—æ®µ
        stats['total_tasks'] = stats.get('total_analyses', 0)
        return stats
    
    async def _task_processor(self) -> None:
        """ä»»åŠ¡å¤„ç†å™¨ä¸»å¾ªç¯"""
        logger.info("ä»»åŠ¡å¤„ç†å™¨å·²å¯åŠ¨")
        
        while self.is_running:
            try:
                # æ§åˆ¶å¹¶å‘æ•°é‡
                if len(self.active_tasks) >= self.max_concurrent_tasks:
                    await asyncio.sleep(0.1)
                    continue
                
                # è·å–ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
                try:
                    task = await asyncio.wait_for(self.task_queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                # å¯åŠ¨ä»»åŠ¡å¤„ç†
                try:
                    asyncio.create_task(self._process_task(task))
                except RuntimeError as e:
                    if "cannot schedule new futures after shutdown" in str(e):
                        logger.warning("äº‹ä»¶å¾ªç¯å·²å…³é—­ï¼Œåœæ­¢åˆ›å»ºæ–°ä»»åŠ¡")
                        break
                    else:
                        raise
                
            except Exception as e:
                logger.error(f"ä»»åŠ¡å¤„ç†å™¨é”™è¯¯: {e}")
                await asyncio.sleep(1.0)
    
    async def _process_task(self, task: AnalysisTask) -> None:
        """å¤„ç†å•ä¸ªåˆ†æä»»åŠ¡"""
        start_time = time.time()
        self.active_tasks[task.task_id] = task
        
        try:
            # æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ
            if not self.is_running:
                logger.warning(f"æœåŠ¡å·²åœæ­¢ï¼Œè·³è¿‡ä»»åŠ¡: {task.task_id}")
                return
            
            logger.info(f"å¼€å§‹å¤„ç†åˆ†æä»»åŠ¡: {task.task_id}")
            
            # ä¿å­˜æˆªå›¾
            screenshot_path = await self._save_task_screenshot(task)
            
            # æ£€æŸ¥VLMæœåŠ¡æ˜¯å¦å¯ç”¨
            if not self.vlm_service or not self.vlm_service.is_available:
                logger.warning(f"VLMæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡åˆ†æä»»åŠ¡: {task.task_id}")
                return
            
            # æ‰§è¡ŒVLMåˆ†æ
            vlm_result = await self.vlm_service.analyze_screenshot_async(
                task.screenshot,
                task.analysis_type,
                task.custom_prompt
            )
            
            # è®¡ç®—åˆ†ææ—¶é•¿
            analysis_duration = time.time() - start_time
            
            # åˆ›å»ºåˆ†æè®°å½•
            record = AnalysisRecord(
                task_id=task.task_id,
                timestamp=task.timestamp,
                screenshot_path=screenshot_path,
                vlm_result=vlm_result,
                analysis_duration=analysis_duration
            )
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self._add_to_history(record)
            
            # ä¿å­˜ç»“æœ
            self.completed_tasks[task.task_id] = vlm_result
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_stats(vlm_result, analysis_duration)
            
            # è°ƒç”¨å›è°ƒå‡½æ•°
            await self._call_callbacks(task.task_id, vlm_result)
            
            # æ‰§è¡Œä»»åŠ¡ç‰¹å®šå›è°ƒ
            if task.callback:
                try:
                    if asyncio.iscoroutinefunction(task.callback):
                        await task.callback(task.task_id, vlm_result)
                    else:
                        task.callback(task.task_id, vlm_result)
                except Exception as e:
                    logger.error(f"ä»»åŠ¡å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
            
            logger.info(f"åˆ†æä»»åŠ¡å®Œæˆ: {task.task_id}, è€—æ—¶: {analysis_duration:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"åˆ†æä»»åŠ¡å¤±è´¥: {task.task_id}, é”™è¯¯: {e}")
            
            # åˆ›å»ºå¤±è´¥ç»“æœ
            failed_result = VLMResult(
                success=False,
                description=f"åˆ†æå¤±è´¥: {str(e)}",
                elements=[],
                suggestions=[],
                confidence=0.0,
                model_name=self.vlm_service.model if self.vlm_service else "unknown",
                processing_time=time.time() - start_time if 'start_time' in locals() else 0.0,
                screen_type="unknown",
                error_message=str(e)
            )
            
            self.completed_tasks[task.task_id] = failed_result
            self.stats["failed_analyses"] += 1
            
        finally:
            # æ¸…ç†æ´»åŠ¨ä»»åŠ¡
            if task.task_id in self.active_tasks:
                del self.active_tasks[task.task_id]
    
    async def _auto_analysis_loop(self) -> None:
        """è‡ªåŠ¨åˆ†æå¾ªç¯"""
        logger.info("è‡ªåŠ¨åˆ†æå¾ªç¯å·²å¯åŠ¨")
        
        while self.auto_analysis_enabled:
            try:
                # æäº¤è‡ªåŠ¨åˆ†æä»»åŠ¡
                await self.analyze_screenshot(
                    analysis_type="game_analysis",
                    priority=0  # ä½ä¼˜å…ˆçº§
                )
                
                # ç­‰å¾…ä¸‹æ¬¡åˆ†æ
                await asyncio.sleep(self.analysis_interval)
                
            except Exception as e:
                logger.error(f"è‡ªåŠ¨åˆ†æé”™è¯¯: {e}")
                await asyncio.sleep(5.0)  # é”™è¯¯åç­‰å¾…æ›´é•¿æ—¶é—´
    
    async def _capture_screenshot(self) -> np.ndarray:
        """è·å–æˆªå›¾"""
        try:
            screenshot = await self.connection.get_screenshot()
            if screenshot is None:
                raise ScreenshotError("æˆªå›¾è·å–å¤±è´¥")
            return screenshot
        except Exception as e:
            logger.error(f"æˆªå›¾è·å–å¤±è´¥: {e}")
            raise ScreenshotError(f"æˆªå›¾è·å–å¤±è´¥: {e}")
    
    async def _save_task_screenshot(self, task: AnalysisTask) -> str:
        """ä¿å­˜ä»»åŠ¡æˆªå›¾"""
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨åˆ†ææˆªå›¾ä¿å­˜
            if not self.config.config.save_analysis_screenshots:
                logger.debug("åˆ†ææˆªå›¾ä¿å­˜å·²ç¦ç”¨ï¼Œè·³è¿‡ä¿å­˜")
                return ""
            
            # æ£€æŸ¥çº¿ç¨‹æ± æ˜¯å¦å¯ç”¨
            if not self.thread_pool or self.thread_pool._shutdown:
                logger.warning("çº¿ç¨‹æ± ä¸å¯ç”¨ï¼Œè·³è¿‡æˆªå›¾ä¿å­˜")
                return ""
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶åæ ¼å¼ï¼Œé¿å…é‡å¤
            timestamp = int(task.timestamp)
            filename = f"analysis_screenshot_{timestamp}.png"
            
            screenshot_dir = self.config.get_screenshot_dir()
            screenshot_path = screenshot_dir / filename
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤ä¿å­˜
            if screenshot_path.exists():
                logger.debug(f"æˆªå›¾æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜: {filename}")
                return str(screenshot_path)
            
            # åœ¨çº¿ç¨‹æ± ä¸­ä¿å­˜æˆªå›¾
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                self.thread_pool,
                save_screenshot,
                task.screenshot,
                str(screenshot_path)
            )
            
            logger.debug(f"åˆ†ææˆªå›¾å·²ä¿å­˜: {filename}")
            return str(screenshot_path)
            
        except RuntimeError as e:
            if "cannot schedule new futures after shutdown" in str(e):
                logger.warning("çº¿ç¨‹æ± å·²å…³é—­ï¼Œè·³è¿‡æˆªå›¾ä¿å­˜")
                return ""
            else:
                logger.error(f"ä¿å­˜æˆªå›¾å¤±è´¥: {e}")
                return ""
        except Exception as e:
            logger.error(f"ä¿å­˜æˆªå›¾å¤±è´¥: {e}")
            return ""
    
    def _add_to_history(self, record: AnalysisRecord) -> None:
        """æ·»åŠ åˆ°å†å²è®°å½•"""
        self.analysis_history.append(record)
        
        # é™åˆ¶å†å²è®°å½•æ•°é‡
        if len(self.analysis_history) > self.analysis_history_limit:
            self.analysis_history = self.analysis_history[-self.analysis_history_limit:]
    
    def _update_stats(self, result: VLMResult, duration: float) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["total_analyses"] += 1
        
        if result.success:
            self.stats["successful_analyses"] += 1
        else:
            self.stats["failed_analyses"] += 1
        
        # æ›´æ–°å¹³å‡æ—¶é•¿
        total = self.stats["total_analyses"]
        current_avg = self.stats["average_duration"]
        self.stats["average_duration"] = (current_avg * (total - 1) + duration) / total
    
    async def _call_callbacks(self, task_id: str, result: VLMResult) -> None:
        """è°ƒç”¨ç»“æœå›è°ƒå‡½æ•°"""
        for callback in self.result_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(task_id, result)
                else:
                    callback(task_id, result)
            except Exception as e:
                logger.error(f"å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
    
    async def _default_result_callback(self, task_id: str, result: VLMResult) -> None:
        """é»˜è®¤ç»“æœè¾“å‡ºå›è°ƒ"""
        try:
            # æ ¼å¼åŒ–è¾“å‡ºåˆ†æç»“æœ
            print("\n" + "="*60)
            print(f"ğŸ“± æˆªå›¾åˆ†æç»“æœ - ä»»åŠ¡ID: {task_id}")
            print("="*60)
            
            if result.success:
                print(f"âœ… åˆ†ææˆåŠŸ (ç½®ä¿¡åº¦: {result.confidence:.2f})")
                print(f"ğŸ® æ¨¡å‹: {result.model_name}")
                
                # æ˜¾ç¤ºä½¿ç”¨çš„æç¤ºè¯
                if result.used_prompt:
                    print(f"ğŸ”¤ ä½¿ç”¨çš„æç¤ºè¯:")
                    # æˆªå–æç¤ºè¯çš„å‰200ä¸ªå­—ç¬¦ä»¥é¿å…è¾“å‡ºè¿‡é•¿
                    prompt_preview = result.used_prompt[:200] + "..." if len(result.used_prompt) > 200 else result.used_prompt
                    print(f"   {prompt_preview}")
                    print()
                
                print(f"ğŸ“ æè¿°: {result.description}")
                
                if result.elements:
                    print(f"\nğŸ¯ å‘ç°å…ƒç´  ({len(result.elements)}ä¸ª):")
                    for i, element in enumerate(result.elements[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                        # å®‰å…¨åœ°è·å–å…ƒç´ å±æ€§ï¼Œæ”¯æŒå­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼
                        if hasattr(element, 'name'):
                            name = element.name
                            element_type = element.element_type.value if hasattr(element.element_type, 'value') else str(element.element_type)
                            position = element.position
                            confidence = element.confidence
                        else:
                            # å¤„ç†å­—å…¸æ ¼å¼çš„å…ƒç´ 
                            name = element.get('name', 'æœªçŸ¥å…ƒç´ ')
                            element_type = element.get('element_type', 'æœªçŸ¥ç±»å‹')
                            position = element.get('position', [0, 0])
                            confidence = element.get('confidence', 0.0)
                        
                        print(f"  {i}. {name} - {element_type} "
                              f"({position[0]}, {position[1]}) "
                              f"ç½®ä¿¡åº¦: {confidence:.2f}")
                
                if result.suggestions:
                    print(f"\nğŸ’¡ æ“ä½œå»ºè®® ({len(result.suggestions)}ä¸ª):")
                    for i, suggestion in enumerate(result.suggestions[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        # å®‰å…¨åœ°è·å–å»ºè®®å±æ€§ï¼Œæ”¯æŒå­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼
                        if hasattr(suggestion, 'action_type'):
                            action_type = suggestion.action_type.value if hasattr(suggestion.action_type, 'value') else str(suggestion.action_type)
                            description = suggestion.description
                            priority = suggestion.priority
                            confidence = suggestion.confidence
                        else:
                            # å¤„ç†å­—å…¸æ ¼å¼çš„å»ºè®®
                            action_type = suggestion.get('action_type', 'æœªçŸ¥åŠ¨ä½œ')
                            description = suggestion.get('description', 'æ— æè¿°')
                            priority = suggestion.get('priority', 1)
                            confidence = suggestion.get('confidence', 0.0)
                        
                        print(f"  {i}. {action_type}: {description} "
                              f"(ä¼˜å…ˆçº§: {priority}, ç½®ä¿¡åº¦: {confidence:.2f})")
            else:
                print(f"âŒ åˆ†æå¤±è´¥: {result.description}")
            
            print("="*60 + "\n")
            
        except Exception as e:
            logger.error(f"é»˜è®¤å›è°ƒè¾“å‡ºå¤±è´¥: {e}")
    
    async def close(self) -> None:
        """å…³é—­åˆ†æç®¡ç†å™¨"""
        logger.info("æ­£åœ¨å…³é—­å¼‚æ­¥åˆ†æç®¡ç†å™¨...")
        
        # è°ƒç”¨stopæ–¹æ³•è¿›è¡Œæ¸…ç†
        await self.stop()
        
        # å…³é—­VLMæœåŠ¡
        if self.vlm_service:
            try:
                await self.vlm_service.close()
            except Exception as e:
                logger.warning(f"å…³é—­VLMæœåŠ¡æ—¶å‡ºé”™: {e}")
        
        logger.info("å¼‚æ­¥åˆ†æç®¡ç†å™¨å·²å…³é—­")