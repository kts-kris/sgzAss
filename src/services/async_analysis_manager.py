#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å¼‚æ­¥æˆªå›¾åˆ†æç®¡ç†å™¨

è´Ÿè´£åè°ƒæˆªå›¾è·å–ã€VLMåˆ†æå’Œç»“æœè¾“å‡ºçš„æ•´ä¸ªå¼‚æ­¥æµç¨‹ã€‚
æä¾›å®æ—¶åˆ†æã€æ‰¹é‡åˆ†æå’Œæ™ºèƒ½è°ƒåº¦åŠŸèƒ½ã€‚
"""

import asyncio
import time
import json
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any, Callable, Coroutine
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor

import numpy as np
from loguru import logger

from .ollama_vlm import OllamaVLMService
from .connection import ConnectionService
from ..models import (
    VLMResult, AnalysisResult, Element, ActionSuggestion,
    VLMError, ScreenshotError
)
from ..utils.config import ConfigManager
from ..utils.helpers import save_screenshot, format_timestamp


@dataclass
class AnalysisTask:
    """åˆ†æä»»åŠ¡æ•°æ®ç±»"""
    task_id: str
    screenshot: np.ndarray
    timestamp: float
    analysis_type: str = "game_analysis"
    custom_prompt: Optional[str] = None
    priority: int = 1
    callback: Optional[Callable] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


@dataclass
class AnalysisRecord:
    """åˆ†æè®°å½•æ•°æ®ç±»"""
    task_id: str
    timestamp: float
    screenshot_path: str
    vlm_result: VLMResult
    analysis_duration: float
    user_feedback: Optional[str] = None
    accuracy_score: Optional[float] = None


class AsyncAnalysisManager:
    """å¼‚æ­¥æˆªå›¾åˆ†æç®¡ç†å™¨"""
    
    def __init__(self, 
                 config_manager: ConfigManager,
                 connection_service: ConnectionService,
                 max_concurrent_tasks: int = 3,
                 analysis_history_limit: int = 100):
        """
        åˆå§‹åŒ–å¼‚æ­¥åˆ†æç®¡ç†å™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
            connection_service: è¿æ¥æœåŠ¡
            max_concurrent_tasks: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
            analysis_history_limit: åˆ†æå†å²è®°å½•é™åˆ¶
        """
        self.config = config_manager
        self.connection = connection_service
        self.max_concurrent_tasks = max_concurrent_tasks
        self.analysis_history_limit = analysis_history_limit
        
        # VLMæœåŠ¡
        self.vlm_service = None
        
        # ä»»åŠ¡é˜Ÿåˆ—å’Œç®¡ç†
        self.task_queue = asyncio.Queue()
        self.active_tasks = {}
        self.completed_tasks = {}
        self.analysis_history = []
        self.history_limit = analysis_history_limit
        
        # æ§åˆ¶æ ‡å¿—
        self.is_running = False
        self.auto_analysis_enabled = False
        self.analysis_interval = 5.0  # è‡ªåŠ¨åˆ†æé—´éš”ï¼ˆç§’ï¼‰
        
        # çº¿ç¨‹æ± ç”¨äºCPUå¯†é›†å‹ä»»åŠ¡
        self.thread_pool = ThreadPoolExecutor(max_workers=2)
        
        # ç»“æœè¾“å‡ºå›è°ƒ
        self.result_callbacks = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "failed_analyses": 0,
            "average_duration": 0.0,
            "prompt_optimizations": 0
        }
    
    async def initialize(self) -> bool:
        """
        åˆå§‹åŒ–åˆ†æç®¡ç†å™¨
        
        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            # åˆå§‹åŒ–VLMæœåŠ¡
            vlm_config = self.config.get_vlm_config()
            self.vlm_service = OllamaVLMService(
                host=vlm_config.host,
                port=vlm_config.port,
                model=vlm_config.model,
                timeout=vlm_config.timeout
            )
            
            if not await self.vlm_service.initialize():
                logger.error("VLMæœåŠ¡åˆå§‹åŒ–å¤±è´¥")
                return False
            
            # å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨
            self.is_running = True
            asyncio.create_task(self._task_processor())
            
            # æ·»åŠ é»˜è®¤ç»“æœè¾“å‡ºå›è°ƒ
            self.add_result_callback(self._default_result_callback)
            
            logger.info("å¼‚æ­¥åˆ†æç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"å¼‚æ­¥åˆ†æç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def start(self) -> bool:
        """å¯åŠ¨å¼‚æ­¥åˆ†æç®¡ç†å™¨"""
        return await self.initialize()
    
    async def stop(self) -> None:
        """åœæ­¢å¼‚æ­¥åˆ†æç®¡ç†å™¨"""
        try:
            self.is_running = False
            self.auto_analysis_enabled = False
            
            # åœæ­¢VLMæœåŠ¡
            if self.vlm_service:
                await self.vlm_service.stop()
            
            # å…³é—­çº¿ç¨‹æ± 
            if self.thread_pool:
                self.thread_pool.shutdown(wait=True)
            
            logger.info("å¼‚æ­¥åˆ†æç®¡ç†å™¨å·²åœæ­¢")
            
        except Exception as e:
            logger.error(f"åœæ­¢å¼‚æ­¥åˆ†æç®¡ç†å™¨å¤±è´¥: {e}")
    
    async def start_auto_analysis(self, interval: float = 5.0) -> None:
        """
        å¯åŠ¨è‡ªåŠ¨æˆªå›¾åˆ†æ
        
        Args:
            interval: åˆ†æé—´éš”ï¼ˆç§’ï¼‰
        """
        self.analysis_interval = interval
        self.auto_analysis_enabled = True
        
        # å¯åŠ¨è‡ªåŠ¨åˆ†æä»»åŠ¡
        asyncio.create_task(self._auto_analysis_loop())
        logger.info(f"è‡ªåŠ¨æˆªå›¾åˆ†æå·²å¯åŠ¨ï¼Œé—´éš”: {interval}ç§’")
    
    async def stop_auto_analysis(self) -> None:
        """åœæ­¢è‡ªåŠ¨æˆªå›¾åˆ†æ"""
        self.auto_analysis_enabled = False
        logger.info("è‡ªåŠ¨æˆªå›¾åˆ†æå·²åœæ­¢")
    
    async def analyze_screenshot(self, 
                               screenshot: Optional[np.ndarray] = None,
                               analysis_type: str = "game_analysis",
                               custom_prompt: Optional[str] = None,
                               priority: int = 1,
                               callback: Optional[Callable] = None) -> str:
        """
        æäº¤æˆªå›¾åˆ†æä»»åŠ¡
        
        Args:
            screenshot: æˆªå›¾æ•°æ®ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨è·å–
            analysis_type: åˆ†æç±»å‹
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            priority: ä»»åŠ¡ä¼˜å…ˆçº§
            callback: å®Œæˆå›è°ƒå‡½æ•°
            
        Returns:
            str: ä»»åŠ¡ID
        """
        try:
            # è·å–æˆªå›¾
            if screenshot is None:
                screenshot = await self._capture_screenshot()
            
            # åˆ›å»ºä»»åŠ¡
            task_id = f"analysis_{int(time.time() * 1000)}"
            task = AnalysisTask(
                task_id=task_id,
                screenshot=screenshot,
                timestamp=time.time(),
                analysis_type=analysis_type,
                custom_prompt=custom_prompt,
                priority=priority,
                callback=callback
            )
            
            # æ·»åŠ åˆ°é˜Ÿåˆ—
            await self.task_queue.put(task)
            logger.info(f"åˆ†æä»»åŠ¡å·²æäº¤: {task_id}")
            
            return task_id
            
        except Exception as e:
            logger.error(f"æäº¤åˆ†æä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def get_analysis_result(self, task_id: str, timeout: float = 60.0) -> Optional[VLMResult]:
        """
        è·å–åˆ†æç»“æœ
        
        Args:
            task_id: ä»»åŠ¡ID
            timeout: è¶…æ—¶æ—¶é—´
            
        Returns:
            VLMResult: åˆ†æç»“æœï¼Œå¦‚æœè¶…æ—¶æˆ–å¤±è´¥åˆ™è¿”å›None
        """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if task_id in self.completed_tasks:
                return self.completed_tasks[task_id]
            
            await asyncio.sleep(0.1)
        
        logger.warning(f"è·å–åˆ†æç»“æœè¶…æ—¶: {task_id}")
        return None
    
    def add_result_callback(self, callback: Callable[[str, VLMResult], None]) -> None:
        """
        æ·»åŠ ç»“æœå›è°ƒå‡½æ•°
        
        Args:
            callback: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶(task_id, result)å‚æ•°
        """
        self.result_callbacks.append(callback)
    
    async def optimize_prompts(self, user_feedback: Optional[str] = None) -> bool:
        """
        åŸºäºå†å²æ•°æ®ä¼˜åŒ–æç¤ºè¯
        
        Args:
            user_feedback: ç”¨æˆ·åé¦ˆ
            
        Returns:
            bool: ä¼˜åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            if len(self.analysis_history) < 5:
                logger.warning("å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæç¤ºè¯ä¼˜åŒ–")
                return False
            
            # å‡†å¤‡å†å²æ•°æ®
            history_data = []
            for record in self.analysis_history[-20:]:  # ä½¿ç”¨æœ€è¿‘20æ¡è®°å½•
                history_data.append({
                    "timestamp": record.timestamp,
                    "scene": record.vlm_result.description,
                    "accuracy": record.accuracy_score or 0.8,
                    "elements_count": len(record.vlm_result.elements),
                    "suggestions_count": len(record.vlm_result.suggestions)
                })
            
            # è°ƒç”¨VLMæœåŠ¡è¿›è¡Œæç¤ºè¯ä¼˜åŒ–
            optimized_prompt = await self.vlm_service.generate_optimized_prompt(
                history_data, user_feedback
            )
            
            # æ›´æ–°æç¤ºè¯æ¨¡æ¿
            self.vlm_service.prompt_templates["game_analysis"] = optimized_prompt
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["prompt_optimizations"] += 1
            
            logger.info("æç¤ºè¯ä¼˜åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {e}")
            return False
    
    async def get_analysis_statistics(self) -> Dict[str, Any]:
        """
        è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        stats = self.stats.copy()
        stats.update({
            "queue_size": self.task_queue.qsize(),
            "active_tasks_count": len(self.active_tasks),
            "history_count": len(self.analysis_history),
            "auto_analysis_enabled": self.auto_analysis_enabled,
            "vlm_service_available": self.vlm_service.is_available if self.vlm_service else False
        })
        return stats
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        stats = self.stats.copy()
        stats.update({
            "queue_size": self.task_queue.qsize(),
            "active_tasks_count": len(self.active_tasks),
            "history_count": len(self.analysis_history),
            "auto_analysis_enabled": self.auto_analysis_enabled,
            "vlm_service_available": self.vlm_service.is_available if self.vlm_service else False
        })
        # æ·»åŠ æµ‹è¯•éœ€è¦çš„å­—æ®µ
        stats['total_tasks'] = stats.get('total_analyses', 0)
        return stats
    
    async def _task_processor(self) -> None:
        """ä»»åŠ¡å¤„ç†å™¨ä¸»å¾ªç¯"""
        logger.info("ä»»åŠ¡å¤„ç†å™¨å·²å¯åŠ¨")
        
        while self.is_running:
            try:
                # æ§åˆ¶å¹¶å‘æ•°é‡
                if len(self.active_tasks) >= self.max_concurrent_tasks:
                    await asyncio.sleep(0.1)
                    continue
                
                # è·å–ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
                try:
                    task = await asyncio.wait_for(self.task_queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                # å¯åŠ¨ä»»åŠ¡å¤„ç†
                asyncio.create_task(self._process_task(task))
                
            except Exception as e:
                logger.error(f"ä»»åŠ¡å¤„ç†å™¨é”™è¯¯: {e}")
                await asyncio.sleep(1.0)
    
    async def _process_task(self, task: AnalysisTask) -> None:
        """å¤„ç†å•ä¸ªåˆ†æä»»åŠ¡"""
        start_time = time.time()
        self.active_tasks[task.task_id] = task
        
        try:
            logger.info(f"å¼€å§‹å¤„ç†åˆ†æä»»åŠ¡: {task.task_id}")
            
            # ä¿å­˜æˆªå›¾
            screenshot_path = await self._save_task_screenshot(task)
            
            # æ‰§è¡ŒVLMåˆ†æ
            vlm_result = await self.vlm_service.analyze_screenshot_async(
                task.screenshot,
                task.analysis_type,
                task.custom_prompt
            )
            
            # è®¡ç®—åˆ†ææ—¶é•¿
            analysis_duration = time.time() - start_time
            
            # åˆ›å»ºåˆ†æè®°å½•
            record = AnalysisRecord(
                task_id=task.task_id,
                timestamp=task.timestamp,
                screenshot_path=screenshot_path,
                vlm_result=vlm_result,
                analysis_duration=analysis_duration
            )
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self._add_to_history(record)
            
            # ä¿å­˜ç»“æœ
            self.completed_tasks[task.task_id] = vlm_result
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_stats(vlm_result, analysis_duration)
            
            # è°ƒç”¨å›è°ƒå‡½æ•°
            await self._call_callbacks(task.task_id, vlm_result)
            
            # æ‰§è¡Œä»»åŠ¡ç‰¹å®šå›è°ƒ
            if task.callback:
                try:
                    if asyncio.iscoroutinefunction(task.callback):
                        await task.callback(task.task_id, vlm_result)
                    else:
                        task.callback(task.task_id, vlm_result)
                except Exception as e:
                    logger.error(f"ä»»åŠ¡å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
            
            logger.info(f"åˆ†æä»»åŠ¡å®Œæˆ: {task.task_id}, è€—æ—¶: {analysis_duration:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"åˆ†æä»»åŠ¡å¤±è´¥: {task.task_id}, é”™è¯¯: {e}")
            
            # åˆ›å»ºå¤±è´¥ç»“æœ
            failed_result = VLMResult(
                success=False,
                description=f"åˆ†æå¤±è´¥: {str(e)}",
                elements=[],
                suggestions=[],
                confidence=0.0,
                model_name=self.vlm_service.model if self.vlm_service else "unknown"
            )
            
            self.completed_tasks[task.task_id] = failed_result
            self.stats["failed_analyses"] += 1
            
        finally:
            # æ¸…ç†æ´»åŠ¨ä»»åŠ¡
            if task.task_id in self.active_tasks:
                del self.active_tasks[task.task_id]
    
    async def _auto_analysis_loop(self) -> None:
        """è‡ªåŠ¨åˆ†æå¾ªç¯"""
        logger.info("è‡ªåŠ¨åˆ†æå¾ªç¯å·²å¯åŠ¨")
        
        while self.auto_analysis_enabled:
            try:
                # æäº¤è‡ªåŠ¨åˆ†æä»»åŠ¡
                await self.analyze_screenshot(
                    analysis_type="game_analysis",
                    priority=0  # ä½ä¼˜å…ˆçº§
                )
                
                # ç­‰å¾…ä¸‹æ¬¡åˆ†æ
                await asyncio.sleep(self.analysis_interval)
                
            except Exception as e:
                logger.error(f"è‡ªåŠ¨åˆ†æé”™è¯¯: {e}")
                await asyncio.sleep(5.0)  # é”™è¯¯åç­‰å¾…æ›´é•¿æ—¶é—´
    
    async def _capture_screenshot(self) -> np.ndarray:
        """è·å–æˆªå›¾"""
        try:
            screenshot = await self.connection.get_screenshot()
            if screenshot is None:
                raise ScreenshotError("æˆªå›¾è·å–å¤±è´¥")
            return screenshot
        except Exception as e:
            logger.error(f"æˆªå›¾è·å–å¤±è´¥: {e}")
            raise ScreenshotError(f"æˆªå›¾è·å–å¤±è´¥: {e}")
    
    async def _save_task_screenshot(self, task: AnalysisTask) -> str:
        """ä¿å­˜ä»»åŠ¡æˆªå›¾"""
        try:
            timestamp_str = format_timestamp(task.timestamp)
            filename = f"analysis_{task.task_id}_{timestamp_str}.png"
            
            screenshot_dir = Path(self.config.get_screenshot_dir())
            screenshot_path = screenshot_dir / filename
            
            # åœ¨çº¿ç¨‹æ± ä¸­ä¿å­˜æˆªå›¾
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                self.thread_pool,
                save_screenshot,
                task.screenshot,
                str(screenshot_path)
            )
            
            return str(screenshot_path)
            
        except Exception as e:
            logger.error(f"ä¿å­˜æˆªå›¾å¤±è´¥: {e}")
            return ""
    
    def _add_to_history(self, record: AnalysisRecord) -> None:
        """æ·»åŠ åˆ°å†å²è®°å½•"""
        self.analysis_history.append(record)
        
        # é™åˆ¶å†å²è®°å½•æ•°é‡
        if len(self.analysis_history) > self.analysis_history_limit:
            self.analysis_history = self.analysis_history[-self.analysis_history_limit:]
    
    def _update_stats(self, result: VLMResult, duration: float) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["total_analyses"] += 1
        
        if result.success:
            self.stats["successful_analyses"] += 1
        else:
            self.stats["failed_analyses"] += 1
        
        # æ›´æ–°å¹³å‡æ—¶é•¿
        total = self.stats["total_analyses"]
        current_avg = self.stats["average_duration"]
        self.stats["average_duration"] = (current_avg * (total - 1) + duration) / total
    
    async def _call_callbacks(self, task_id: str, result: VLMResult) -> None:
        """è°ƒç”¨ç»“æœå›è°ƒå‡½æ•°"""
        for callback in self.result_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(task_id, result)
                else:
                    callback(task_id, result)
            except Exception as e:
                logger.error(f"å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
    
    async def _default_result_callback(self, task_id: str, result: VLMResult) -> None:
        """é»˜è®¤ç»“æœè¾“å‡ºå›è°ƒ"""
        try:
            # æ ¼å¼åŒ–è¾“å‡ºåˆ†æç»“æœ
            print("\n" + "="*60)
            print(f"ğŸ“± æˆªå›¾åˆ†æç»“æœ - ä»»åŠ¡ID: {task_id}")
            print("="*60)
            
            if result.success:
                print(f"âœ… åˆ†ææˆåŠŸ (ç½®ä¿¡åº¦: {result.confidence:.2f})")
                print(f"ğŸ® æ¨¡å‹: {result.model_name}")
                print(f"ğŸ“ æè¿°: {result.description}")
                
                if result.elements:
                    print(f"\nğŸ¯ å‘ç°å…ƒç´  ({len(result.elements)}ä¸ª):")
                    for i, element in enumerate(result.elements[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"  {i}. {element.name} - {element.element_type.value} "
                              f"({element.position[0]}, {element.position[1]}) "
                              f"ç½®ä¿¡åº¦: {element.confidence:.2f}")
                
                if result.suggestions:
                    print(f"\nğŸ’¡ æ“ä½œå»ºè®® ({len(result.suggestions)}ä¸ª):")
                    for i, suggestion in enumerate(result.suggestions[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"  {i}. {suggestion.action_type.value}: {suggestion.description} "
                              f"(ä¼˜å…ˆçº§: {suggestion.priority}, ç½®ä¿¡åº¦: {suggestion.confidence:.2f})")
            else:
                print(f"âŒ åˆ†æå¤±è´¥: {result.description}")
            
            print("="*60 + "\n")
            
        except Exception as e:
            logger.error(f"é»˜è®¤å›è°ƒè¾“å‡ºå¤±è´¥: {e}")
    
    async def close(self) -> None:
        """å…³é—­åˆ†æç®¡ç†å™¨"""
        logger.info("æ­£åœ¨å…³é—­å¼‚æ­¥åˆ†æç®¡ç†å™¨...")
        
        # åœæ­¢è‡ªåŠ¨åˆ†æ
        self.auto_analysis_enabled = False
        
        # åœæ­¢ä»»åŠ¡å¤„ç†å™¨
        self.is_running = False
        
        # ç­‰å¾…æ´»åŠ¨ä»»åŠ¡å®Œæˆ
        while self.active_tasks:
            logger.info(f"ç­‰å¾… {len(self.active_tasks)} ä¸ªæ´»åŠ¨ä»»åŠ¡å®Œæˆ...")
            await asyncio.sleep(1.0)
        
        # å…³é—­VLMæœåŠ¡
        if self.vlm_service:
            await self.vlm_service.close()
        
        # å…³é—­çº¿ç¨‹æ± 
        self.thread_pool.shutdown(wait=True)
        
        logger.info("å¼‚æ­¥åˆ†æç®¡ç†å™¨å·²å…³é—­")